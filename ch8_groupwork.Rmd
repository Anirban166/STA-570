---
title: "STA 570 -- Ch. 8 Homework"
author: "Brit Riggs"
date: "`r format(Sys.time(),  '%B %d, %Y')`"
output: pdf_document
---

```{r, message = FALSE, warning = FALSE, echo = FALSE}
suppressPackageStartupMessages({
  library(boot)
  library(knitr)
  library(dplyr)
  library(tidyr)
  library(mosaic)
  library(ggplot2)
  library(latex2exp)
})
```

## Exercise 1

### (a)
Answer: \textbf{Done (GOT IT)}

```{r}
# i. P(F 5,5 < 1/2)
pf(1/2, 5, 5)
# ii. P(F 5,5 > 2/1)
1-pf(2, 5, 5)
# iii. P(F 4,10 > 6/1)
1-pf(6, 4, 10)
# iv. P(F 10,4 < 1/6)
pf(1/6, 10, 4)
```

### (b)
Answer: \textbf{Done (GOT IT)}

Part (i) and (ii) are equal and part (iii) and (iv) are equal because the F Distribution is symmetrical.

## Exercise 2

### (a)
Answer: \textbf{Done (GOT IT)}

```{r}
sample_sizes <- c(5, 25, 100, 400)
final_data <- data.frame(trial = numeric(), nvalue = numeric(), 
                         pvalue = numeric(), statistic = numeric())
for (size in sample_sizes) {
  for (i in 1:10) {
    n <- size
    x <- rnorm(n, mean = 25, sd = 5)
    temp_case <- data.frame(trial = i, nvalue = n, 
                            pvalue = shapiro.test(x)$p.value, 
                            statistic = shapiro.test(x)$statistic)
    final_data <- rbind(final_data, temp_case)
  }
}
n_5   <- data.frame(final_data[1:10,],  row.names = c(1:10))
n_25  <- data.frame(final_data[11:20,], row.names = c(1:10))
n_100 <- data.frame(final_data[21:30,], row.names = c(1:10))
n_400 <- data.frame(final_data[31:40,], row.names = c(1:10))
kables(
  list(kable(n_5),kable(n_25),kable(n_100),kable(n_400))
)
```
The results are that even with a small sample size, the shapiro test is pretty consistent at detecting normality.
The test is more consistent with a larger sample size.

### (b)
Answer: \textbf{Done (GOT IT)}

```{r}
sample_sizes <- c(5, 25, 100, 400)
final_data <- data.frame(trial = numeric(), nvalue = numeric(), 
                         pvalue = numeric(), statistic = numeric())
for (size in sample_sizes) {
  for (i in 1:10) {
    n <- size
    x <- rgamma(n, shape = 3, rate = 2)
    temp_case <- data.frame(trial = i, nvalue = n, 
                            pvalue = shapiro.test(x)$p.value, 
                            statistic = shapiro.test(x)$statistic)
    final_data <- rbind(final_data, temp_case)
  }
}
n_5   <- data.frame(final_data[1:10,],  row.names = c(1:10))
n_25  <- data.frame(final_data[11:20,], row.names = c(1:10))
n_100 <- data.frame(final_data[21:30,], row.names = c(1:10))
n_400 <- data.frame(final_data[31:40,], row.names = c(1:10))
kables(
  list(kable(n_5),kable(n_25),kable(n_100),kable(n_400))
)
```
The results are that the shapiro test is bad at detecting the non-normality of the gamma function at smaller
sample sizes which is why the p-value is higher for sample sizes 5 and 25. The test is great at detecting
non-normality at sizes 100 and 400 which is why the p-value is smaller at these sample sizes.

## Exercise 3

### (a)
Answer: \textbf{Done (GOT IT)}

```{r}
final_data <- data.frame(n = numeric(), num_rejects_out_of_20 = numeric())
sample_sizes <- c(5,25,50,100,500)
for (size in sample_sizes){
  n <- size
  reject <- 0
  for (i in 1:20) {
    sigma <- c(2,2)
    my.data <- data.frame(y = c(rnorm(n, mean = 0, sd = sigma[1]),
                                rnorm(n, mean = 0, sd = sigma[2])),
                          group = c(rep(’g1’, n), rep(’g2’, n)))
    pvalue <- var.test(y ~ group, data = my.data)$p.value
    if (pvalue < 0.05) {
      reject <- reject+1
  }
}
temp_data <- data.frame(n=n, num_rejects_out_of_20=reject)
final_data <- rbind(final_data, temp_data)
}
final_data
```

The F test rejects that the variances equal rarely when the two variances are equal (see table which counts
the number of null rejects out of 20 trials for each sample size n). The sample size does not appear to affect
the rejection rate.

### (b)
Answer: \textbf{Done (GOT IT)}

```{r}
final_data <- data.frame(n = numeric(), num_rejects_out_of_1000 = numeric())
sample_sizes <- c(5,25,50,100,500)
for (size in sample_sizes){
  n <- size
  reject <- 0
  for (i in 1:1000) {
    sigma <- c(2,4)
    my.data <- data.frame(y = c(rnorm(n, mean = 0, sd = sigma[1]),
                                rnorm(n, mean = 0, sd = sigma[2])),
                          group = c(rep(’g1’, n), rep(’g2’, n)))
    pvalue <- var.test(y ~ group, data = my.data)$p.value
    if (pvalue < 0.05) {
      reject <- reject+1
  }
}
temp_data <- data.frame(n=n, num_rejects_out_of_1000=reject)
final_data <- rbind(final_data, temp_data)
}
final_data
```

The f-test rejects more frequently.

### (c)
Answer: \textbf{Done (GOT IT)}

```{r}
par(mfrow = c(1, 1)) # 1 row of 1: Just one graph
n <- 50 
sigma <- c(2, 2)     # Standard deviations of each group
my.data <- data.frame(y = c(rnorm(n, mean = 0, sd = sigma[1]),
                            rnorm(n, mean = 0, sd = sigma[2])),
                      group = c(rep('g1', n), rep('g2', n)))
boxplot(y ~ group, data = my.data) 
var.test(y ~ group, data = my.data)
```

As the sample size increases, the box widths become more consistent.

## Exercise 4

### (a)
Answer: \textbf{Done (GOT IT)}

```{r}
# H0 : var1 = var2
# Ha : var1 not equal to var2
n1    <- 15
xbar1 <- 52
s1    <- 7
n2    <- 20
xbar2 <- 42
s2    <- 4
f <- s1^2/s2^2
2 * (1 - pf(f, n1 - 1, n2 - 1))
```

At 5% significance, we reject the null hypothesis because the p-value is smaller than alpha.

## Exercise 5

### (a)
Answer: \textbf{Done (GOT IT)}

```{r}
lifespan <- data.frame(
  time = c(19.25, 19.7, 19.75, 19.9, 19.95, 20.05, 20.13, 20.2, 20.4, 20.6,
           9.7, 9.75, 9.8, 9.82, 9.85, 9.90, 9.92, 9.96, 10.01, 10.02, 10.10,
           10.11, 10.13, 10.19, 10.28, 10.31),
  type = c( rep('110', 10), rep('220', 16)))
Group1Data <- lifespan %>% filter(type == '110')
Group2Data <- lifespan %>% filter(type == '220')
```

Mean and variance of each sample group:

```{r}
c(mean(Group1Data$time), var(Group1Data$time), length(Group1Data$time))
c(mean(Group2Data$time), var(Group2Data$time), length(Group2Data$time))
```

### (b)
Answer: \textbf{Done (GOT IT)}

(i)
```{r}
qqnorm(Group1Data$time)
qqline(Group1Data$time)
```      
I observe that Group 1 is normally distributed.
```{r}      
qqnorm(Group2Data$time)
qqline(Group2Data$time)
```
I observe that Group 2 is normally distributed as well.

(ii)
```{r}
shapiro.test(Group1Data$time)
shapiro.test(Group2Data$time)
```

The large p-values in each case tell me that my assumptions for both Group 1 and Group 2 are right.

### (c)
Answer: \textbf{Done (GOT IT)}

(i) Calculating the standard deviations:
```{r}
c(sd(Group1Data$time), sd(Group2Data$time))
```

Calculating the f-statistic:
```{r}
f = (sd(Group1Data$time) / sd(Group2Data$time))^2
```

Calculating the p-value:
```{r}
2 * (1 - pf(f, 9, 15))
```

(ii) 

```{r}
var.test(time ~ type, data = lifespan)
```
From the observed test result, I verify that my calculations are right. (complying with the values I obtained in (i))
